{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WFRCR0DlOSjB",
        "ifjgn8IYO3cx",
        "2QMa6rEzQCvy",
        "2Ox0U7xkrjBt"
      ],
      "authorship_tag": "ABX9TyMncLlqj3/RT1QAGNOiTS1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ransjnr/building-ai-agents-with-autogen/blob/main/Creating_sophisticated_agents_with_nested_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "faErSxjXNUCy",
        "outputId": "c03f500f-9ca9-4e2d-9ff1-270beed61545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ag2\n",
            "  Downloading ag2-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from ag2)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from ag2)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from ag2)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2) (2.11.4)\n",
            "Collecting python-dotenv (from ag2)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2) (3.4.2)\n",
            "Downloading ag2-0.9.0-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, diskcache, docker, asyncer, ag2\n",
            "Successfully installed asyncer-0.0.8 diskcache-5.6.3 docker-7.1.0 ag2-0.9.0 python-dotenv-1.1.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.77.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ag2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##import requried libraries\n",
        "\n",
        "import os\n",
        "from autogen import ConversableAgent, UserProxyAgent, AssistantAgent\n",
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "og-wgUnTNcg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "model_name = \"o4-mini\"\n",
        "deployment = \"o4-mini-deployment\"\n",
        "\n",
        "subscription_key = userdata.get(\"AZURE_OPENAI_KEY\")\n",
        "api_version = \"2024-12-01-preview\""
      ],
      "metadata": {
        "id": "0KbEbtmSNkZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"config_list\": [\n",
        "        {\n",
        "            \"model\": deployment,\n",
        "            \"base_url\": endpoint,\n",
        "            \"api_type\": \"azure\",\n",
        "            \"api_key\": subscription_key,\n",
        "            \"api_version\": api_version,\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "niuqEOnRNv5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Writing Agent"
      ],
      "metadata": {
        "id": "WFRCR0DlOSjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = AssistantAgent(\n",
        "    name=\"Writer\",\n",
        "    system_message=\"You are a writer. You write engaging and concise \"\n",
        "                   \"blogpost (with title) on given topics. You must polish your \"\n",
        "                   \"writing based on the feedback you receive and give a refined \"\n",
        "                   \"version. Only return your final work without additional comments.\",\n",
        "    llm_config=llm_config,\n",
        ")"
      ],
      "metadata": {
        "id": "YtYbanCIN29e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task"
      ],
      "metadata": {
        "id": "ifjgn8IYO3cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task='''\n",
        "      Write a concise but engaging blogpost about GPUs.\n",
        "      Make sure the blogpost is within 100 words.\n",
        "      '''"
      ],
      "metadata": {
        "id": "izD-SdneOw03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = writer.generate_reply(messages=[{\"content\": task, \"role\": \"user\"}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfdFAREoPDZf",
        "outputId": "93628ae4-f145-43a8-d93d-44deaf30aa2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 05-13 03:30:55] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEtRQSGTPdlG",
        "outputId": "748827cb-5386-4384-d89e-06dcdde9d7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: How GPUs Power the Future of Computing\n",
            "\n",
            "In today’s digital age, Graphics Processing Units (GPUs) are the unsung heroes powering everything from lifelike video games to breakthrough AI research. Unlike traditional CPUs, GPUs excel at parallel processing, tackling thousands of tasks simultaneously—ideal for rendering complex visuals, crunching scientific data, and training neural networks. As industries demand higher performance and efficiency, GPUs evolve with specialized cores and smarter architectures. Whether you’re a gamer, a data scientist, or a content creator, embracing GPU technology means unlocking faster speeds, richer experiences, and unprecedented innovation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simple review of the post"
      ],
      "metadata": {
        "id": "2QMa6rEzQCvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviewer = AssistantAgent(\n",
        "    name = \"Reviewer\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are a reviewer. You review the work of \"\n",
        "                  \"the writer and provide constructive \"\n",
        "                  \"feedbackto help improve the quality of the content.\",\n",
        ")"
      ],
      "metadata": {
        "id": "8miqCZtzPgpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = reviewer.initiate_chat(\n",
        "    recipient=writer,\n",
        "    message=task,\n",
        "    max_turns=2,\n",
        "    summary_method=\"last_msg\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EtF5xKGQioZ",
        "outputId": "92c74771-497f-4e95-ceeb-2b94bed5f93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewer (to Writer):\n",
            "\n",
            "\n",
            "      Write a concise but engaging blogpost about GPUs.\n",
            "      Make sure the blogpost is within 100 words.\n",
            "      \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:31:16] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writer (to Reviewer):\n",
            "\n",
            "Unleashing the Power of GPUs\n",
            "\n",
            "Graphics processing units (GPUs) have transformed modern computing, accelerating everything from gaming to scientific simulations. Originally designed to render images, today’s GPUs deploy thousands of cores to tackle complex parallel tasks, powering AI, machine learning, and data analytics. Their massive throughput and energy efficiency make them indispensable in research labs, animation studios, and cryptocurrency mining. As developers optimize algorithms to harness GPU capabilities, we stand on the brink of breakthroughs in virtual reality, deep learning, and beyond. Embrace the GPU revolution and unlock limitless computational potential.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:31:30] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewer (to Writer):\n",
            "\n",
            "You’ve hit most of the marks: it’s short, clear and uses strong verbs (“accelerating,” “powering,” “unlock”) that keep the reader’s interest. A few thoughts to push it even further:\n",
            "\n",
            "1. Lead with a hook  \n",
            "   Instead of the title alone, try opening with a vivid snapshot or question (“Ever watched a 3D world come to life in an instant?”) to draw readers in immediately.\n",
            "\n",
            "2. Define jargon sparingly  \n",
            "   Words like “throughput” and “parallel tasks” might lose non-technical readers. Consider swapping in plain-English phrases (“raw speed,” “many calculations at once”) or briefly explaining them.\n",
            "\n",
            "3. Add a concrete example  \n",
            "   Mention a familiar GPU-powered game, a popular AI application, or a record-breaking benchmark to make the technology feel tangible.\n",
            "\n",
            "4. Tighten the close  \n",
            "   Your final line is strong, but you could make it more actionable—perhaps invite readers to try a GPU-powered demo or link to a beginner’s guide.\n",
            "\n",
            "Overall it’s a compelling snapshot of GPUs’ impact. A sharper hook and one vivid example will make it truly memorable.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:31:43] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writer (to Reviewer):\n",
            "\n",
            "Unleashing GPU Power\n",
            "\n",
            "Ever watched a 3D world come to life in an instant? GPUs—specialized chips originally built for rendering graphics in games like Fortnite—now deliver raw speed by handling thousands of calculations at once. Beyond gaming, they power AI tools such as ChatGPT, accelerate scientific research, and drive real-time virtual reality. Thanks to their energy-efficient design, GPUs are a staple in animation studios, data centers, and crypto mining rigs. Ready to explore? Try a free GPU-powered demo or dive into our beginner’s guide to get started today.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (4363185a-7c50-4083-872c-ffe0f67acc5d): Maximum turns (2) reached\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adding multi-level review using nested chats\n"
      ],
      "metadata": {
        "id": "2Ox0U7xkrjBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEO_reviewer = AssistantAgent (\n",
        "    name=\"SEO_reviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"As an SEO expert, your role is to analyze and enhance content for optimal search engine performance. \"\n",
        "                   \"Focus on providing actionable recommendations that boost rankings and drive organic traffic. \"\n",
        "                   \"Limit your feedback to 3 key points, ensuring they are specific and directly applicable. \"\n",
        "                   \"Start each review by introducing yourself as an SEO Reviewer.\",\n",
        ")"
      ],
      "metadata": {
        "id": "vYYMxUE0QuOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grammatical_error_reviewer = AssistantAgent(\n",
        "    name=\"GrammaticalErrorReviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"As a grammar specialist, your task is to meticulously examine content \"\n",
        "                   \"for grammatical errors, punctutation mistakes, and style inconsistencies. \"\n",
        "                   \"Provide up to 3 key points addressing the most significant grammatical issues. \"\n",
        "                   \"Ensure your feedback is specific, actionable, and includes examples where appropriate. \"\n",
        "                   \"Begin each review by introducing yourself as a Grammatical Error Reviewer. \",\n",
        ")"
      ],
      "metadata": {
        "id": "Fnk2CFslsJa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethics_reviewer = AssistantAgent(\n",
        "    name=\"EthicsReviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"As an ethics specialist, your role is to evaluate content for ethical integrity \"\n",
        "                  \"and identify any potential moral concerns. \"\n",
        "                  \"Provide up to 3 specific, actionable recommendations to address ethical isues. \"\n",
        "                  \"Ensure your feedback is concise and directly applicable. \"\n",
        "                  \"Start each review by introducing yourself as an Ethics Reviewer.\",\n",
        ")"
      ],
      "metadata": {
        "id": "mTX-tho3tXQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_reviewer = AssistantAgent(\n",
        "    name=\"MetaReviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message = \"You are a meta reviewer, you aggregate and review \"\n",
        "                     \"the work of other reviewers and give a final sugestion on the content. \",\n",
        ")"
      ],
      "metadata": {
        "id": "-rSVQmIzuAau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Orchestrating the nested chat"
      ],
      "metadata": {
        "id": "IsEn0aWhuXLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reflection_message(recipient, messags, sender, config):\n",
        "  return f'''Review the following content.\n",
        "        \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}'''\n",
        "\n",
        "review_chats = [\n",
        "    {\n",
        "        \"recipient\": SEO_reviewer,\n",
        "        \"message\": reflection_message,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_args\": {\"summary_prompt\" :\n",
        "            \"Return review into as JSON object only:\"\n",
        "            \"{'Reviewer': '', 'Review': ''}. Here Reviewer should be your role\",},\n",
        "        \"max_turns\": 1,\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": grammatical_error_reviewer,\n",
        "        \"message\": reflection_message,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_args\": {\"summary_prompt\" :\n",
        "            \"Return review into as JSON object only:\"\n",
        "            \"{'Reviewer': '', 'Review': ''}.\",},\n",
        "        \"max_turns\": 1,\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": ethics_reviewer,\n",
        "        \"message\": reflection_message,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_args\": {\"summary_prompt\" :\n",
        "            \"Return review into as JSON object only:\"\n",
        "            \"{'Reviewer': '', 'Review': ''}. Here Reviewer should be your role\",},\n",
        "        \"max_turns\": 1,\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": meta_reviewer,\n",
        "        \"message\": \"Aggregate feedback from all reviewers and give final suggestions on the writing.\",\n",
        "        \"max_turns\": 1,\n",
        "    }\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Zc-wWYcuuU9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviewer.register_nested_chats(\n",
        "    review_chats,\n",
        "    trigger=writer,\n",
        ")"
      ],
      "metadata": {
        "id": "x4h-lC89xj8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = reviewer.initiate_chat(\n",
        "    recipient=writer,\n",
        "    message=task,\n",
        "    max_turns=2,\n",
        "    summary_method=\"last_msg\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EvsaEx5x-Dr",
        "outputId": "5c031323-2120-437c-e30e-1d6b606d1383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewer (to Writer):\n",
            "\n",
            "\n",
            "      Write a concise but engaging blogpost about GPUs.\n",
            "      Make sure the blogpost is within 100 words.\n",
            "      \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:55:20] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writer (to Reviewer):\n",
            "\n",
            "Title: Unleashing GPU Power\n",
            "\n",
            "Graphics Processing Units (GPUs) have revolutionized computing by handling massive parallel tasks at incredible speeds. Originally designed for rendering 3D graphics in gaming, modern GPUs now drive AI research, data science, cryptocurrency mining, and scientific simulations. Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing. With cloud providers and consumer markets embracing GPU acceleration, developers can harness unparalleled performance for everything from immersive virtual realities to groundbreaking medical discoveries. GPUs truly power the next frontier of innovation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Reviewer (to SEO_reviewer):\n",
            "\n",
            "Review the following content.    \n",
            "        \n",
            "\n",
            " Title: Unleashing GPU Power\n",
            "\n",
            "Graphics Processing Units (GPUs) have revolutionized computing by handling massive parallel tasks at incredible speeds. Originally designed for rendering 3D graphics in gaming, modern GPUs now drive AI research, data science, cryptocurrency mining, and scientific simulations. Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing. With cloud providers and consumer markets embracing GPU acceleration, developers can harness unparalleled performance for everything from immersive virtual realities to groundbreaking medical discoveries. GPUs truly power the next frontier of innovation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:55:31] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEO_reviewer (to Reviewer):\n",
            "\n",
            "SEO Reviewer\n",
            "\n",
            "1. Target and Embed Long-Tail Keywords  \n",
            "   - Research high-value phrases like “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”  \n",
            "   - Revise the title to include your primary keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”).  \n",
            "   - Sprinkle these long-tail terms in at least one H2, the first 100 words, and naturally throughout the body (aim for a 1–2% keyword density).\n",
            "\n",
            "2. Improve Content Structure and Readability  \n",
            "   - Break the text into clear sections with H2/H3 headings (e.g., “H2: How GPUs Speed Up Deep Learning,” “H2: GPU Use Cases in Science & Industry,” “H3: Real-Time Ray Tracing Benefits”).  \n",
            "   - Convert benefits into a bulleted list to boost scannability (e.g., “• Thousands of parallel cores… • Reduced computation times…”).  \n",
            "   - Add a brief intro paragraph that sets user intent (“In this guide, you’ll learn how modern GPUs turbocharge…”) and a concluding call-to-action (“Explore our GPU buying guide” or “Download your free GPU benchmarking toolkit”).\n",
            "\n",
            "3. Optimize On-Page Elements and Rich Snippets  \n",
            "   - Write a concise meta description (around 150 characters) that includes your primary keyword and a value proposition:  \n",
            "     “Discover how GPU acceleration drives AI research, gaming, and HPC—learn benefits, use cases, and best practices.”  \n",
            "   - Add descriptive alt text to any images (e.g., “Diagram of GPU core parallel processing”).  \n",
            "   - Implement FAQ or HowTo schema by adding a 3-question FAQ at the end (e.g., “What is GPU acceleration?”, “Which industries benefit most?”, “How to choose the right GPU?”) to qualify for rich snippets and improve CTR.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (bed9a776-a0d7-4366-a2b8-3a531450eb54): Maximum turns (1) reached\n",
            "[autogen.oai.client: 05-13 03:55:43] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Reviewer (to GrammaticalErrorReviewer):\n",
            "\n",
            "Review the following content.    \n",
            "        \n",
            "\n",
            " Title: Unleashing GPU Power\n",
            "\n",
            "Graphics Processing Units (GPUs) have revolutionized computing by handling massive parallel tasks at incredible speeds. Originally designed for rendering 3D graphics in gaming, modern GPUs now drive AI research, data science, cryptocurrency mining, and scientific simulations. Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing. With cloud providers and consumer markets embracing GPU acceleration, developers can harness unparalleled performance for everything from immersive virtual realities to groundbreaking medical discoveries. GPUs truly power the next frontier of innovation.\n",
            "Context: \n",
            "{\"Reviewer\":\"SEO Reviewer\",\"Review\":\"1. Target and Embed Long-Tail Keywords:\\n- Research high-value phrases like “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”\\n- Revise the title to include your primary keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”).\\n- Sprinkle these long-tail terms in at least one H2, the first 100 words, and naturally throughout the body (aim for a 1–2% keyword density).\\n\\n2. Improve Content Structure and Readability:\\n- Break the text into clear sections with H2/H3 headings (e.g., “H2: How GPUs Speed Up Deep Learning,” “H2: GPU Use Cases in Science & Industry,” “H3: Real-Time Ray Tracing Benefits”).\\n- Convert benefits into a bulleted list to boost scannability.\\n- Add a brief intro paragraph that sets user intent and a concluding call-to-action (“Explore our GPU buying guide” or “Download your free GPU benchmarking toolkit”).\\n\\n3. Optimize On-Page Elements and Rich Snippets:\\n- Write a concise meta description (~150 characters) including your primary keyword and a value proposition.\\n- Add descriptive alt text to images (e.g., “Diagram of GPU core parallel processing”).\\n- Implement FAQ or HowTo schema by adding a 3-question FAQ at the end to qualify for rich snippets and improve CTR.\"}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:56:24] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GrammaticalErrorReviewer (to Reviewer):\n",
            "\n",
            "I am a Grammatical Error Reviewer. Here are the three most significant issues and how to fix them:\n",
            "\n",
            "1. Adverb vs. adjective misuse  \n",
            "   – Issue: “massive parallel tasks” implies the tasks are large rather than being executed in parallel.  \n",
            "   – Fix: Change to “massively parallel tasks” to correctly use the adverb for manner.  \n",
            "     Example:  \n",
            "     Original: “…by handling massive parallel tasks at incredible speeds.”  \n",
            "     Revised:  “…by handling massively parallel tasks at incredible speeds.”\n",
            "\n",
            "2. Awkward pronoun-led sentence  \n",
            "   – Issue: Beginning with “Their thousands of cores…” buries the true subject (GPUs) and can read as vague.  \n",
            "   – Fix: Lead with the noun “GPUs” or use a prepositional phrase for clarity.  \n",
            "     Example:  \n",
            "     Original: “Their thousands of cores process complex calculations simultaneously…”  \n",
            "     Revised:  “With thousands of cores, GPUs process complex calculations simultaneously…”\n",
            "\n",
            "3. Overly long, comma-heavy sentence  \n",
            "   – Issue: The third sentence strings together multiple ideas with commas, which can hamper readability.  \n",
            "   – Fix: Break it into two concise sentences.  \n",
            "     Example:  \n",
            "     Original: “Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”  \n",
            "     Revised:  “GPUs’ thousands of cores process calculations simultaneously. This design slashes computation times and unlocks breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (7243c1f8-2256-4b37-85c9-774b195e8076): Maximum turns (1) reached\n",
            "[autogen.oai.client: 05-13 03:56:39] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Reviewer (to EthicsReviewer):\n",
            "\n",
            "Review the following content.    \n",
            "        \n",
            "\n",
            " Title: Unleashing GPU Power\n",
            "\n",
            "Graphics Processing Units (GPUs) have revolutionized computing by handling massive parallel tasks at incredible speeds. Originally designed for rendering 3D graphics in gaming, modern GPUs now drive AI research, data science, cryptocurrency mining, and scientific simulations. Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing. With cloud providers and consumer markets embracing GPU acceleration, developers can harness unparalleled performance for everything from immersive virtual realities to groundbreaking medical discoveries. GPUs truly power the next frontier of innovation.\n",
            "Context: \n",
            "{\"Reviewer\":\"SEO Reviewer\",\"Review\":\"1. Target and Embed Long-Tail Keywords:\\n- Research high-value phrases like “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”\\n- Revise the title to include your primary keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”).\\n- Sprinkle these long-tail terms in at least one H2, the first 100 words, and naturally throughout the body (aim for a 1–2% keyword density).\\n\\n2. Improve Content Structure and Readability:\\n- Break the text into clear sections with H2/H3 headings (e.g., “H2: How GPUs Speed Up Deep Learning,” “H2: GPU Use Cases in Science & Industry,” “H3: Real-Time Ray Tracing Benefits”).\\n- Convert benefits into a bulleted list to boost scannability.\\n- Add a brief intro paragraph that sets user intent and a concluding call-to-action (“Explore our GPU buying guide” or “Download your free GPU benchmarking toolkit”).\\n\\n3. Optimize On-Page Elements and Rich Snippets:\\n- Write a concise meta description (~150 characters) including your primary keyword and a value proposition.\\n- Add descriptive alt text to images (e.g., “Diagram of GPU core parallel processing”).\\n- Implement FAQ or HowTo schema by adding a 3-question FAQ at the end to qualify for rich snippets and improve CTR.\"}\n",
            "{\"Reviewer\":\"Grammatical Error Reviewer\",\"Review\":\"1. Adverb vs. adjective misuse – Issue: “massive parallel tasks” implies the tasks are large rather than being executed in parallel. Fix: Change to “massively parallel tasks” to correctly use the adverb for manner. Example: Original: “…by handling massive parallel tasks at incredible speeds.” Revised: “…by handling massively parallel tasks at incredible speeds.”\\n2. Awkward pronoun-led sentence – Issue: Beginning with “Their thousands of cores…” buries the true subject (GPUs) and can read as vague. Fix: Lead with the noun “GPUs” or use a prepositional phrase for clarity. Example: Original: “Their thousands of cores process complex calculations simultaneously…” Revised: “With thousands of cores, GPUs process complex calculations simultaneously…”\\n3. Overly long, comma-heavy sentence – Issue: The third sentence strings together multiple ideas with commas, which can hamper readability. Fix: Break it into two concise sentences. Example: Original: “Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing.” Revised: “GPUs’ thousands of cores process calculations simultaneously. This design slashes computation times and unlocks breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”\"}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:56:48] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EthicsReviewer (to Reviewer):\n",
            "\n",
            "Ethics Reviewer:\n",
            "\n",
            "The GPU overview is informative, but it omits several ethical considerations around resource use, supply chains, and dual-use. Here are three actionable recommendations to strengthen its ethical integrity:\n",
            "\n",
            "1. Highlight Environmental Impact  \n",
            "   • Acknowledge GPUs’ high power consumption—especially in crypto-mining and AI training—and suggest energy-efficient models or use of renewable energy.  \n",
            "   • Recommend linking to carbon-offset programs or industry benchmarks (e.g., J per teraFLOP) so readers can compare sustainability metrics.\n",
            "\n",
            "2. Address Responsible Sourcing  \n",
            "   • Note that GPU production relies on minerals (e.g., cobalt) with potential links to child labor and conflict zones.  \n",
            "   • Encourage vendors to adopt “conflict-free” certifications and publish their supply-chain audits, or to support fair-trade mineral initiatives.\n",
            "\n",
            "3. Promote Ethical Use of GPU-Powered AI  \n",
            "   • Advise developers to follow established AI ethics guidelines (e.g., fairness, transparency, privacy) when deploying GPU-accelerated models.  \n",
            "   • Suggest including a brief call-out about mitigating bias, securing data, and preventing misuse in surveillance or deep-fake generation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (d8bfd204-7b2d-45e9-9431-006dad841741): Maximum turns (1) reached\n",
            "[autogen.oai.client: 05-13 03:57:09] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Reviewer (to MetaReviewer):\n",
            "\n",
            "Aggregate feedback from all reviewers and give final suggestions on the writing.\n",
            "Context: \n",
            "{\"Reviewer\":\"SEO Reviewer\",\"Review\":\"1. Target and Embed Long-Tail Keywords:\\n- Research high-value phrases like “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”\\n- Revise the title to include your primary keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”).\\n- Sprinkle these long-tail terms in at least one H2, the first 100 words, and naturally throughout the body (aim for a 1–2% keyword density).\\n\\n2. Improve Content Structure and Readability:\\n- Break the text into clear sections with H2/H3 headings (e.g., “H2: How GPUs Speed Up Deep Learning,” “H2: GPU Use Cases in Science & Industry,” “H3: Real-Time Ray Tracing Benefits”).\\n- Convert benefits into a bulleted list to boost scannability.\\n- Add a brief intro paragraph that sets user intent and a concluding call-to-action (“Explore our GPU buying guide” or “Download your free GPU benchmarking toolkit”).\\n\\n3. Optimize On-Page Elements and Rich Snippets:\\n- Write a concise meta description (~150 characters) including your primary keyword and a value proposition.\\n- Add descriptive alt text to images (e.g., “Diagram of GPU core parallel processing”).\\n- Implement FAQ or HowTo schema by adding a 3-question FAQ at the end to qualify for rich snippets and improve CTR.\"}\n",
            "{\"Reviewer\":\"Grammatical Error Reviewer\",\"Review\":\"1. Adverb vs. adjective misuse – Issue: “massive parallel tasks” implies the tasks are large rather than being executed in parallel. Fix: Change to “massively parallel tasks” to correctly use the adverb for manner. Example: Original: “…by handling massive parallel tasks at incredible speeds.” Revised: “…by handling massively parallel tasks at incredible speeds.”\\n2. Awkward pronoun-led sentence – Issue: Beginning with “Their thousands of cores…” buries the true subject (GPUs) and can read as vague. Fix: Lead with the noun “GPUs” or use a prepositional phrase for clarity. Example: Original: “Their thousands of cores process complex calculations simultaneously…” Revised: “With thousands of cores, GPUs process complex calculations simultaneously…”\\n3. Overly long, comma-heavy sentence – Issue: The third sentence strings together multiple ideas with commas, which can hamper readability. Fix: Break it into two concise sentences. Example: Original: “Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing.” Revised: “GPUs’ thousands of cores process calculations simultaneously. This design slashes computation times and unlocks breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”\"}\n",
            "{\"Reviewer\":\"Ethics Reviewer\",\"Review\":\"The GPU overview is informative, but it omits several ethical considerations around resource use, supply chains, and dual-use. Here are three actionable recommendations to strengthen its ethical integrity:\\n\\n1. Highlight Environmental Impact\\n• Acknowledge GPUs’ high power consumption—especially in crypto-mining and AI training—and suggest energy-efficient models or use of renewable energy.\\n• Recommend linking to carbon-offset programs or industry benchmarks (e.g., J per teraFLOP) so readers can compare sustainability metrics.\\n\\n2. Address Responsible Sourcing\\n• Note that GPU production relies on minerals (e.g., cobalt) with potential links to child labor and conflict zones.\\n• Encourage vendors to adopt “conflict-free” certifications and publish their supply-chain audits, or to support fair-trade mineral initiatives.\\n\\n3. Promote Ethical Use of GPU-Powered AI\\n• Advise developers to follow established AI ethics guidelines (e.g., fairness, transparency, privacy) when deploying GPU-accelerated models.\\n• Suggest including a brief call-out about mitigating bias, securing data, and preventing misuse in surveillance or deep-fake generation.\"}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:57:25] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MetaReviewer (to Reviewer):\n",
            "\n",
            "Below is a consolidated set of recommendations organized by focus area. Applying these changes will improve search visibility, clarity, and ethical rigor while keeping your prose tight and reader-friendly.\n",
            "\n",
            "1. Structure & SEO  \n",
            "• Title & Keywords – Revise the title to include your primary long-tail keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”). Target terms such as “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”  \n",
            "• Headings & Flow – Break into clear H2/H3 sections:  \n",
            "  – H2: Introduction to GPU Acceleration  \n",
            "  – H2: How GPUs Speed Up Deep Learning  \n",
            "  – H2: GPU Use Cases in Science & Industry  \n",
            "  – H3: Real-Time Ray Tracing Benefits  \n",
            "• Intro & CTA – Add a 1–2 sentence intro stating user intent (“Discover how GPU acceleration can slash your AI training times…”) and a concluding call-to-action (“Explore our GPU buying guide” or “Download the free benchmarking toolkit”).  \n",
            "• Bullets & Scannability – Convert lists of benefits or use cases into bullet points so readers can skim easily.\n",
            "\n",
            "2. On-Page Optimization  \n",
            "• Meta Description – Craft a ~150-character summary incorporating your primary keyword and a hook (“Unleash AI research with GPU acceleration—compare top GPUs now”).  \n",
            "• Images & Alt Text – Ensure every graphic has descriptive alt text (e.g., “Diagram of GPU core parallel processing”).  \n",
            "• Schema Markup – Add a 3-question FAQ block at the end (with answers) and implement FAQ or HowTo schema to boost your chances for rich snippets.\n",
            "\n",
            "3. Grammar & Style  \n",
            "• Adverb vs. Adjective – Change “massive parallel tasks” to “massively parallel tasks.”  \n",
            "• Sentence Clarity – Replace pronoun‐led openings like “Their thousands of cores…” with “With thousands of cores, GPUs process complex calculations simultaneously.”  \n",
            "• Split Long Sentences – Break up comma-heavy lines. For example:  \n",
            "  Original: “Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”  \n",
            "  Revised: “GPUs’ thousands of cores process calculations simultaneously. This design slashes computation times and unlocks breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”\n",
            "\n",
            "4. Ethical Considerations  \n",
            "• Environmental Impact – Call out GPUs’ high power draw in AI training and crypto-mining. Recommend energy-efficient models or renewable-powered data centers and link to carbon-offset or efficiency benchmarks (e.g., joules per teraFLOP).  \n",
            "• Responsible Sourcing – Note reliance on minerals (e.g., cobalt) linked to conflict zones. Encourage vendors to obtain “conflict-free” certification and support fair-trade initiatives.  \n",
            "• Ethical AI Use – Include a brief sidebar or call-out advising developers to follow AI ethics guidelines (fairness, transparency, privacy) and to guard against misuse (deep-fakes, surveillance).\n",
            "\n",
            "By integrating these changes, your article will be optimized for search, free of common grammatical pitfalls, and strengthened with ethical context—positioning it to rank well and serve readers responsibly.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (624ae549-d379-42a7-8fca-d3ea98955a23): Maximum turns (1) reached\n",
            "Reviewer (to Writer):\n",
            "\n",
            "Below is a consolidated set of recommendations organized by focus area. Applying these changes will improve search visibility, clarity, and ethical rigor while keeping your prose tight and reader-friendly.\n",
            "\n",
            "1. Structure & SEO  \n",
            "• Title & Keywords – Revise the title to include your primary long-tail keyword (e.g., “Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing”). Target terms such as “GPU acceleration for AI research,” “best GPUs for deep learning,” or “cloud GPU computing solutions.”  \n",
            "• Headings & Flow – Break into clear H2/H3 sections:  \n",
            "  – H2: Introduction to GPU Acceleration  \n",
            "  – H2: How GPUs Speed Up Deep Learning  \n",
            "  – H2: GPU Use Cases in Science & Industry  \n",
            "  – H3: Real-Time Ray Tracing Benefits  \n",
            "• Intro & CTA – Add a 1–2 sentence intro stating user intent (“Discover how GPU acceleration can slash your AI training times…”) and a concluding call-to-action (“Explore our GPU buying guide” or “Download the free benchmarking toolkit”).  \n",
            "• Bullets & Scannability – Convert lists of benefits or use cases into bullet points so readers can skim easily.\n",
            "\n",
            "2. On-Page Optimization  \n",
            "• Meta Description – Craft a ~150-character summary incorporating your primary keyword and a hook (“Unleash AI research with GPU acceleration—compare top GPUs now”).  \n",
            "• Images & Alt Text – Ensure every graphic has descriptive alt text (e.g., “Diagram of GPU core parallel processing”).  \n",
            "• Schema Markup – Add a 3-question FAQ block at the end (with answers) and implement FAQ or HowTo schema to boost your chances for rich snippets.\n",
            "\n",
            "3. Grammar & Style  \n",
            "• Adverb vs. Adjective – Change “massive parallel tasks” to “massively parallel tasks.”  \n",
            "• Sentence Clarity – Replace pronoun‐led openings like “Their thousands of cores…” with “With thousands of cores, GPUs process complex calculations simultaneously.”  \n",
            "• Split Long Sentences – Break up comma-heavy lines. For example:  \n",
            "  Original: “Their thousands of cores process complex calculations simultaneously, slashing computation times and unlocking breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”  \n",
            "  Revised: “GPUs’ thousands of cores process calculations simultaneously. This design slashes computation times and unlocks breakthroughs in deep learning, real-time ray tracing, and high-performance computing.”\n",
            "\n",
            "4. Ethical Considerations  \n",
            "• Environmental Impact – Call out GPUs’ high power draw in AI training and crypto-mining. Recommend energy-efficient models or renewable-powered data centers and link to carbon-offset or efficiency benchmarks (e.g., joules per teraFLOP).  \n",
            "• Responsible Sourcing – Note reliance on minerals (e.g., cobalt) linked to conflict zones. Encourage vendors to obtain “conflict-free” certification and support fair-trade initiatives.  \n",
            "• Ethical AI Use – Include a brief sidebar or call-out advising developers to follow AI ethics guidelines (fairness, transparency, privacy) and to guard against misuse (deep-fakes, surveillance).\n",
            "\n",
            "By integrating these changes, your article will be optimized for search, free of common grammatical pitfalls, and strengthened with ethical context—positioning it to rank well and serve readers responsibly.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 05-13 03:58:05] {696} WARNING - Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model o4-mini is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writer (to Reviewer):\n",
            "\n",
            "Title: Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing\n",
            "\n",
            "## Introduction to GPU Acceleration  \n",
            "Discover how GPU acceleration can slash AI training times by leveraging massively parallel cores.\n",
            "\n",
            "## How GPUs Speed Up Deep Learning  \n",
            "With thousands of cores, GPUs process calculations simultaneously:  \n",
            "• Faster model training  \n",
            "• Real-time data analysis  \n",
            "\n",
            "## GPU Use Cases in Science & Industry  \n",
            "• AI research & deep learning  \n",
            "• Cloud GPU computing solutions  \n",
            "\n",
            "### Real-Time Ray Tracing Benefits  \n",
            "Experience lifelike graphics in gaming and simulations.  \n",
            "\n",
            "Ready to turbocharge your projects? Explore our GPU buying guide.  \n",
            "Choose energy-efficient models and conflict-free sourcing; follow AI ethics guidelines for responsible use.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (48676b34-0d8f-4617-9158-7ae9c3a570a1): Maximum turns (2) reached\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myW01bKeyDu8",
        "outputId": "037bdd15-6b23-464b-a7ac-f770e5a7abab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Unleashing GPU Power: GPU Acceleration for AI Research & High-Performance Computing\n",
            "\n",
            "## Introduction to GPU Acceleration  \n",
            "Discover how GPU acceleration can slash AI training times by leveraging massively parallel cores.\n",
            "\n",
            "## How GPUs Speed Up Deep Learning  \n",
            "With thousands of cores, GPUs process calculations simultaneously:  \n",
            "• Faster model training  \n",
            "• Real-time data analysis  \n",
            "\n",
            "## GPU Use Cases in Science & Industry  \n",
            "• AI research & deep learning  \n",
            "• Cloud GPU computing solutions  \n",
            "\n",
            "### Real-Time Ray Tracing Benefits  \n",
            "Experience lifelike graphics in gaming and simulations.  \n",
            "\n",
            "Ready to turbocharge your projects? Explore our GPU buying guide.  \n",
            "Choose energy-efficient models and conflict-free sourcing; follow AI ethics guidelines for responsible use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8cbzBuTyTkH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}